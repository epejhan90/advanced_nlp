{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "initial_train_attempt_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, filepath):\n",
        "        cwd = os.getcwd()\n",
        "        self.basepath = filepath\n",
        "        try:\n",
        "            os.stat(self.basepath+\"/add_prim_split\")\n",
        "            os.stat(self.basepath+\"/few_shot_split\")\n",
        "            os.stat(self.basepath+\"/filler_split\")\n",
        "            os.stat(self.basepath+\"/length_split\")\n",
        "            os.stat(self.basepath+\"/simple_split\")\n",
        "            os.stat(self.basepath+\"/template_split\")\n",
        "        except Exception as e:\n",
        "            raise Exception(\"Path \"+filepath+\" doesnt seem to contain the required folders.\")\n",
        "\n",
        "    def load_1a(self):\n",
        "        train = self.file_loader(\"/simple_split/tasks_train_simple.txt\")\n",
        "        test = self.file_loader(\"/simple_split/tasks_test_simple.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_1b(self):\n",
        "        percentile_dict = {}\n",
        "        splits = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\", \"64\"]\n",
        "\n",
        "        for percentile in splits:\n",
        "            train = self.file_loader(\"/simple_split/size_variations/tasks_train_simple_p{}.txt\".format(percentile))\n",
        "            test = self.file_loader(\"/simple_split/size_variations/tasks_test_simple_p{}.txt\".format(percentile))\n",
        "            \n",
        "            percentile_dict[percentile] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return percentile_dict\n",
        "\n",
        "    def load_2(self):\n",
        "        train = self.file_loader(\"/length_split/tasks_train_length.txt\")\n",
        "        test = self.file_loader(\"/length_split/tasks_test_length.txt\")\n",
        "\n",
        "        return (np.asarray(train), np.asarray(test))\n",
        "\n",
        "    def load_3(self):\n",
        "        \"\"\"\n",
        "        loads the datasets for both parts of the experiment\n",
        "        the first part where both primitives appear without compositional commands\n",
        "        the second part where 'jump' primitive appears in\n",
        "        compositional commands of varying lengths\n",
        "        returns a dictionary of pairs all possible train/test sets\n",
        "        \"\"\"\n",
        "        data_dict = {}\n",
        "        nums = [\"1\", \"2\", \"4\", \"8\", \"16\", \"32\"]\n",
        "        reps = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_jump.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_jump.txt\")\n",
        "        data_dict['jump'] = (np.asarray(train), np.asarray(test))\n",
        "\n",
        "        train = self.file_loader(\"/add_prim_split/tasks_train_addprim_turn_left.txt\")\n",
        "        test = self.file_loader(\"/add_prim_split/tasks_test_addprim_turn_left.txt\")\n",
        "        data_dict['lturn'] = (np.asarray(train), np.asarray(test))\n",
        "        \n",
        "        for num in nums:\n",
        "            for rep in reps:\n",
        "                train = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_train_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                test = self.file_loader(\"/add_prim_split/with_additional_examples/tasks_test_addprim_complex_jump_num{}_rep{}.txt\".format(num, rep))\n",
        "                \n",
        "                data_dict['jump_num{}_rep{}'.format(num, rep)] = (np.asarray(train), np.asarray(test))\n",
        "            \n",
        "        return data_dict\n",
        "\n",
        "    def file_loader(self, path):\n",
        "        sent_list = []\n",
        "        with open(self.basepath+path, \"r\") as f:\n",
        "                    for line in f:\n",
        "                        sent_list.append(line_splitter(line))\n",
        "        return sent_list\n",
        "\n",
        "    \n",
        "def line_splitter(sentence):\n",
        "    sent_list = sentence.split(\"OUT: \")\n",
        "    sent_list[0] = sent_list[0].strip(\"IN: \")\n",
        "    sent_list[1] = sent_list[1].strip(\"\\n\")\n",
        "\n",
        "    return sent_list\n",
        "\n",
        "# examples:\n",
        "# 1a :\n",
        "#   train, test = dl.load_1a()\n",
        "#   train[0][0] first train sentence, \"IN\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "# 1b :\n",
        "#   dict = dl.load_1b()\n",
        "#   train, test = dict[\"1\"] extract the 1 percentile sentences out, split into train and test\n",
        "#   train[0][0] first train sentence, \"OUT\"\n",
        "#   train[0][1] first train sentence, \"OUT\"\n",
        "#\n",
        "# all returns are numpy arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from data_loader import DataLoader\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Input:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        #self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.index2word = {}\n",
        "        #self.n_words = 2  # Count SOS and EOS\n",
        "        self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "class Output:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        #self.index2word = {}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "        #self.n_words = 0\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "\n",
        "        \n",
        "def get_embedding(word, lookup_dict, embeds):\n",
        "    tensor = torch.tensor([lookup_dict[word]], dtype=torch.long)\n",
        "    return embeds(tensor)\n",
        "\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair, input_lang, output_lang):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "100000\nFalse\n0.03256230672200521\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\n2.204344514510611\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\n1.494958736636503\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nTrue\nhello\nTrue\nhello\nTrue\nhello\nTrue\nhello\nFalse\nFalse\n1.3973697424897684\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nTrue\nhello\nFalse\nFalse\nFalse\n"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f9e826541a17>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, train_data, input_lang, output_lang, max_length, learning_rate, mode)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f9e826541a17>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, clipping_value, mode)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecoder_hidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f9e826541a17>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CustomLoss(torch.autograd.Function):  \n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        import ipdb; ipdb.set_trace()\n",
        "        #pass\n",
        "        return\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.0, layers=1, mode='RNN'):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "        if mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        elif mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, max_length, dropout_p=0.0, layers=1, attention=False, mode='RNN'):\n",
        "    \t#layers should be either 1 or 2\n",
        "    \t#in the latter case remember to pass a pair of hidden states!\n",
        "    \t#mode can be either 'LSTM', 'GRU' or 'RNN'\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.layers = layers\n",
        "        self.max_length = max_length\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "\n",
        "        if self.attention:\n",
        "\t        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "\t        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "        self.hidden_layer = nn.RNN(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "\n",
        "        if mode == 'LSTM':\n",
        "        \tself.hidden_layer = nn.LSTM(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        elif mode == 'GRU':\n",
        "        \tself.hidden_layer = nn.GRU(self.hidden_size, self.hidden_size, num_layers=self.layers)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs=None):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        if self.attention:\n",
        "\t        attn_weights = F.softmax(\n",
        "\t            self.attn(torch.cat((output[0], hidden[0]), 1)), dim=1)\n",
        "\t        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "\t                                 encoder_outputs.unsqueeze(0))\n",
        "\t        output = torch.cat((output[0], attn_applied[0]), 1)\n",
        "        \toutput = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.hidden_layer(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        hidden = torch.zeros(self.layers, 1, self.hidden_size, device=device)\n",
        "        nn.init.xavier_uniform_(hidden, gain=nn.init.calculate_gain('relu'))\n",
        "        return hidden\n",
        "\n",
        "def train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, clipping_value=5, mode='RNN'):\n",
        "    encoder_hidden1 = encoder.initHidden()\n",
        "    encoder_hidden2 = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    output_length = output_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        if mode == 'LSTM':\n",
        "            encoder_output, (encoder_hidden1, encoder_hidden2) = encoder(input_tensor[ei], (encoder_hidden1, encoder_hidden2))\n",
        "        else: \n",
        "            encoder_output, encoder_hidden1 = encoder(input_tensor[ei], encoder_hidden1)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "    \n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden1 = encoder_hidden1\n",
        "    decoder_hidden2 = encoder_hidden2\n",
        "\n",
        "    forcing = random.random() > 0.5\n",
        "\n",
        "    if forcing:\n",
        "        for di in range(output_length):\n",
        "            if mode == 'LSTM':\n",
        "                decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2))\n",
        "            else:\n",
        "                decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden)\n",
        "            decoder_input = output_tensor[di]\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "    else:\n",
        "        for di in range(output_length):\n",
        "            if mode == 'LSTM':\n",
        "                decoder_output, (decoder_hidden1, decoder_hidden2) = decoder(decoder_input, (decoder_hidden1, decoder_hidden2))\n",
        "            else:\n",
        "                decoder_output, decoder_hidden1 = decoder(decoder_input, decoder_hidden1, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "            loss += criterion(decoder_output, output_tensor[di])\n",
        "            \n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    #loss = CustomLoss\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), clipping_value)\n",
        "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), clipping_value)\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    \n",
        "    return loss.item() / output_length\n",
        "\n",
        "    \n",
        "def trainIters(encoder, decoder, train_data, input_lang, output_lang, max_length, learning_rate=0.001, mode='RNN'):\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    losses = []\n",
        "    print(train_data.shape[0])\n",
        "    print_loss_total = 0\n",
        "\n",
        "    for iter in range(train_data.shape[0]):\n",
        "        training_pair = tensorsFromPair(train_data[iter], input_lang, output_lang)\n",
        "        input_tensor = training_pair[0]\n",
        "        output_tensor = training_pair[1]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "            output_tensor = output_tensor.cuda()\n",
        "        \n",
        "        loss = train(input_tensor, output_tensor, encoder, encoder_optimizer, decoder, decoder_optimizer, criterion, max_length, mode=mode)\n",
        "        losses.append(loss)\n",
        "        print_loss_total += loss\n",
        "\n",
        "        if iter % 100 == 0:\n",
        "            print_loss_avg = print_loss_total / 100\n",
        "            print(print_loss_avg)\n",
        "            print_loss_total = 0\n",
        "\n",
        "    return losses\n",
        "\n",
        "#dl = DataLoader(\"/content/drive/My Drive/SCAN\")\n",
        "dl = DataLoader(\"SCAN\")\n",
        "train_data, test_data = dl.load_1a()\n",
        "\n",
        "MAX_LENGTH = max([len(x[0].split()) for x in train_data]) + 1\n",
        "\n",
        "train_in = Input(\"train_input\")\n",
        "train_out = Output(\"train_output\")\n",
        "\n",
        "test_in = Input(\"test_input\")\n",
        "test_out = Output(\"test_output\")\n",
        "\n",
        "for datapoint in train_data:\n",
        "        train_in.addSentence(datapoint[0])\n",
        "        train_out.addSentence(datapoint[1])\n",
        "\n",
        "for datapoint in test_data:\n",
        "        test_in.addSentence(datapoint[0])\n",
        "        test_out.addSentence(datapoint[1])\n",
        "\n",
        "model = \"LSTM\"\n",
        "\n",
        "train_data = train_data[np.random.choice(train_data.shape[0], 100000, replace=True), :]\n",
        "\n",
        "encoder = Encoder(25, 25, mode=model)\n",
        "decoder = Decoder(25, 25, max_length=MAX_LENGTH, mode=model)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   encoder.cuda()\n",
        "   decoder.cuda()\n",
        "\n",
        "%time losses = trainIters(encoder, decoder, train_data, train_in, train_out, MAX_LENGTH, mode=model)\n",
        "print(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "pxmS4rEHL366",
        "outputId": "7c144b71-43bf-454f-a369-df7b5bb776e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "62\n",
            "200\n",
            "132\n",
            "300\n",
            "205\n",
            "400\n",
            "275\n",
            "500\n",
            "342\n",
            "600\n",
            "414\n",
            "700\n",
            "481\n",
            "800\n",
            "552\n",
            "900\n",
            "627\n",
            "1000\n",
            "705\n",
            "1100\n",
            "781\n",
            "1200\n",
            "845\n",
            "1300\n",
            "920\n",
            "1400\n",
            "990\n",
            "1500\n",
            "1068\n",
            "1600\n",
            "1136\n",
            "1700\n",
            "1213\n",
            "1800\n",
            "1282\n",
            "1900\n",
            "1358\n",
            "2000\n",
            "1431\n",
            "2100\n",
            "1504\n",
            "2200\n",
            "1582\n",
            "2300\n",
            "1658\n",
            "2400\n",
            "1732\n",
            "2500\n",
            "1800\n",
            "2600\n",
            "1877\n",
            "2700\n",
            "1947\n",
            "2800\n",
            "2024\n",
            "2900\n",
            "2097\n",
            "3000\n",
            "2173\n",
            "3100\n",
            "2244\n",
            "3200\n",
            "2321\n",
            "3300\n",
            "2394\n",
            "3400\n",
            "2474\n",
            "3500\n",
            "2548\n",
            "3600\n",
            "2621\n",
            "3700\n",
            "2702\n",
            "3800\n",
            "2784\n",
            "3900\n",
            "2861\n",
            "4000\n",
            "2942\n",
            "4100\n",
            "3015\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "#from data_loader import *\n",
        "#from embeddings import *\n",
        "#from layers_attempt import *\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        if torch.cuda.is_available():\n",
        "            input_tensor = input_tensor.cuda()\n",
        "            \n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        \n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                #decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        return decoded_words\n",
        "\n",
        "def evaluateIters(test_data, encoder, decoder, lang_in, lang_out):\n",
        "    miss = 0\n",
        "    iters = 0\n",
        "\n",
        "    for test_point in test_data:\n",
        "        pred = evaluate(encoder, decoder, test_point[0], lang_in, lang_out)\n",
        "        pred = \" \".join(pred)\n",
        "        if pred != test_point[1]:\n",
        "            miss += 1\n",
        "        iters += 1\n",
        "\n",
        "        if iters % 100 == 0:\n",
        "            print(iters)\n",
        "            print(miss)\n",
        "\n",
        "    return miss\n",
        "\n",
        "missed = evaluateIters(test_data, encoder, decoder, train_in, train_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "9auy0X5hXmD8",
        "outputId": "1b0752d4-768d-4832-998c-0f78079afa5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_RIGHT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT I_TURN_LEFT'"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\" \".join(evaluate(encoder, decoder, test_data[4000][0], train_in, train_out)) #3742"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "EG638DGIa-je",
        "outputId": "2ef8e446-d0c6-4e9e-df70-9386e416b213"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'turn left thrice after turn opposite right twice'"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[4000][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "OFn0WQ1kU0VG",
        "outputId": "bd34bec0-3b01-4241-9f7a-1ceb74ab466c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max([len(x[0].split()) for x in train_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jJcgD6Z4VaFS"
      },
      "outputs": [],
      "source": []
    }
  ]
}